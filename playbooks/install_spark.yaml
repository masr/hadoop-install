- name: Install spark for config group {{ config_group_name }}
  hosts: "{{ variable_hosts | default('all') }}"
  tasks:
    - name: load vars
      include_vars: file="{{ vars_file | default('vars/default.yaml') }}"

    - import_tasks: include/before_install_service.yaml
      vars:
        service_user: spark

    - name: sync spark release
      unarchive: src=../releases/{{ spark_release_tarball }} dest={{ hadoop_releases_dir }} owner=root group=root mode=0755
      when: (sync_release is not defined) or (sync_release is defined and sync_release|bool)

    - name: create spark soft link
      file: src={{ hadoop_releases_dir }}/{{ spark_release_version }} path={{ install_base_dir }}/spark state=link


    - name: create spark confs dir
      file: path={{ item }} state=directory mode=0755 owner=root group=hadoop
      with_items:
        - "{{ hadoop_confs_dir }}/spark/conf"

    - name: sync spark confs
      copy: src={{ group_conf_dir }}/{{ item }} dest={{ hadoop_confs_dir }}/spark/conf/{{ item }} mode=0644 owner=root group=hadoop
      with_items:
        - log4j.properties
        - spark-defaults.conf
        - spark-env.sh

    - name: delete original spark/conf
      file: path={{ install_base_dir }}/spark/conf state=absent

    - name: create spark conf soft link
      file: src={{ hadoop_confs_dir }}/spark/conf path={{ install_base_dir }}/spark/conf state=link

    - import_tasks: include/install_systemd_service.yml
      vars:
        service_name: sparkhistoryserver


