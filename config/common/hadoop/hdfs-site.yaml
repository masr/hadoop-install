dfs.nameservices: "{{ default_nameservice }}"
dfs.ha.namenodes.{{ default_nameservice }}: nn1,nn2
dfs.ha.fencing.methods: shell(/bin/true)
dfs.ha.automatic-failover.enabled: "true"

dfs.namenode.rpc-address.{{ default_nameservice }}.nn1: "{{ namenode1 }}:{{ namenode_client_rpc_port }}"
dfs.namenode.rpc-address.{{ default_nameservice }}.nn2: "{{ namenode2 }}:{{ namenode_client_rpc_port }}"
dfs.namenode.servicerpc-address.{{ default_nameservice }}.nn1: "{{ namenode1 }}:{{ namenode_service_rpc_port }}"
dfs.namenode.servicerpc-address.{{ default_nameservice }}.nn2: "{{ namenode2 }}:{{ namenode_service_rpc_port }}"
dfs.namenode.https-address.{{ default_nameservice }}.nn1: "{{ namenode1 }}:{{ namenode_http_port }}"
dfs.namenode.https-address.{{ default_nameservice }}.nn2: "{{ namenode2 }}:{{ namenode_http_port }}"
dfs.namenode.http-address.{{ default_nameservice }}.nn1: "{{ namenode1 }}:{{ namenode_http_port }}"
dfs.namenode.http-address.{{ default_nameservice }}.nn2: "{{ namenode2 }}:{{ namenode_http_port }}"
dfs.namenode.handler.count: 32
dfs.namenode.service.handler.count: 32
dfs.namenode.safemode.threshold-pct: 1.0f
#dfs.namenode.name.dir: "{{ dfs_namenode_name_dir }}"
dfs.namenode.shared.edits.dir: "{{ qjournal_quorum }}"

dfs.permissions.superusergroup: hadoop
dfs.permissions.enabled: "true"
dfs.replication: 3
dfs.http.policy: "{{ http_policy }}"


#dfs.datanode.data.dir: "{{ dfs_datanode_data_dir }}"
dfs.datanode.failed.volumes.tolerated: 0
dfs.datanode.data.dir.perm: 700
dfs.datanode.address: "{{ inventory_hostname }}:{{ datanode_port }}"
dfs.datanode.ipc.address: "{{ inventory_hostname }}:{{ datanode_ipc_port }}"
dfs.datanode.http.address: "{{ inventory_hostname }}:{{ datanode_http_port }}"
dfs.datanode.du.reserved: 1073741824

dfs.block.local-path-access.user: hdfs hadoop
dfs.domain.socket.path: "{{ dfs_domain_socket_path }}"

dfs.hosts: "{{ hadoop_confs_dir }}/hadoop/conf/hdfs-include"
dfs.hosts.exclude: "{{ hadoop_confs_dir }}/hadoop/conf/hdfs-exclude"

dfs.client.read.shortcircuit: "true"
dfs.cluster.administrators: hdfs
dfs.client.failover.proxy.provider.{{ default_nameservice }}: org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider

dfs.journalnode.edits.dir: "{{ dfs_journalnode_edits_dir }}"